{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3caa6f30",
   "metadata": {},
   "source": [
    "<img align=\"right\" style=\"padding-left:50px;\" src=\"figures_wk4/data_cleaning.png\" width=350><br>\n",
    "### User Bias in Data Cleaning\n",
    "For your homework assignment this week, we will explore how our treatment of our data can impact the quality of our results.\n",
    "\n",
    "**Dataset:**\n",
    "The data is a Salary Survey from AskAManager.org. It’s US-centric-ish but does allow for a range of country inputs.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e411bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "960098db-5807-4f89-85b4-be34e2a80484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('survey_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb64b9a-0236-4153-9dc1-560c873d2a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28108 entries, 0 to 28107\n",
      "Data columns (total 18 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   timestamp  28108 non-null  object \n",
      " 1   q1         28108 non-null  object \n",
      " 2   q2         28033 non-null  object \n",
      " 3   q3         28107 non-null  object \n",
      " 4   q4         7273 non-null   object \n",
      " 5   q5         28108 non-null  object \n",
      " 6   q6         20793 non-null  float64\n",
      " 7   q7         28108 non-null  object \n",
      " 8   q8         211 non-null    object \n",
      " 9   q9         3047 non-null   object \n",
      " 10  q10        28108 non-null  object \n",
      " 11  q11        23074 non-null  object \n",
      " 12  q12        28026 non-null  object \n",
      " 13  q13        28108 non-null  object \n",
      " 14  q14        28108 non-null  object \n",
      " 15  q15        27885 non-null  object \n",
      " 16  q16        27937 non-null  object \n",
      " 17  q17        27931 non-null  object \n",
      "dtypes: float64(1), object(17)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59804474-eb37-41f7-b958-1c604a24586d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q3</th>\n",
       "      <th>q4</th>\n",
       "      <th>q5</th>\n",
       "      <th>q6</th>\n",
       "      <th>q7</th>\n",
       "      <th>q8</th>\n",
       "      <th>q9</th>\n",
       "      <th>q10</th>\n",
       "      <th>q11</th>\n",
       "      <th>q12</th>\n",
       "      <th>q13</th>\n",
       "      <th>q14</th>\n",
       "      <th>q15</th>\n",
       "      <th>q16</th>\n",
       "      <th>q17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp     q1                             q2  \\\n",
       "0  4/27/2021 11:02:10  25-34   Education (Higher Education)   \n",
       "1  4/27/2021 11:02:22  25-34              Computing or Tech   \n",
       "2  4/27/2021 11:02:38  25-34  Accounting, Banking & Finance   \n",
       "3  4/27/2021 11:02:41  25-34                     Nonprofits   \n",
       "4  4/27/2021 11:02:42  25-34  Accounting, Banking & Finance   \n",
       "\n",
       "                                         q3   q4      q5      q6   q7   q8  \\\n",
       "0        Research and Instruction Librarian  NaN  55,000     0.0  USD  NaN   \n",
       "1  Change & Internal Communications Manager  NaN  54,600  4000.0  GBP  NaN   \n",
       "2                      Marketing Specialist  NaN  34,000     NaN  USD  NaN   \n",
       "3                           Program Manager  NaN  62,000  3000.0  USD  NaN   \n",
       "4                        Accounting Manager  NaN  60,000  7000.0  USD  NaN   \n",
       "\n",
       "    q9             q10             q11          q12           q13  \\\n",
       "0  NaN   United States   Massachusetts       Boston     5-7 years   \n",
       "1  NaN  United Kingdom             NaN    Cambridge  8 - 10 years   \n",
       "2  NaN              US       Tennessee  Chattanooga   2 - 4 years   \n",
       "3  NaN             USA       Wisconsin    Milwaukee  8 - 10 years   \n",
       "4  NaN              US  South Carolina   Greenville  8 - 10 years   \n",
       "\n",
       "           q14              q15         q16    q17  \n",
       "0    5-7 years  Master's degree       Woman  White  \n",
       "1    5-7 years   College degree  Non-binary  White  \n",
       "2  2 - 4 years   College degree       Woman  White  \n",
       "3    5-7 years   College degree       Woman  White  \n",
       "4    5-7 years   College degree       Woman  White  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce58c7-0e14-4426-a4b7-96805ea64bbb",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "Your goal for this assignment is to observe how your data treatment during the cleaning process can skew or bias the dataset.\n",
    "\n",
    "Before diving right in, stop and read through the questions associated with the dataset. As you can see, they are either free-form text entries or categorical selections. Knowing this, perform some exploratory data analysis (EDA) to investigate the \"state\" of the dataset.\n",
    "\n",
    "[Add as many code cell below here as needs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a848f6e-a0e2-43a2-90fa-76821daed60c",
   "metadata": {},
   "source": [
    "**Question:** How would you describe the \"state\" of this dataset? Be specific and detailed in your answer. (Think paragraphs rather than sentences).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae74cdd-3467-44d8-a068-7c5743a30a3e",
   "metadata": {},
   "source": [
    "### State of the Dataset: A Detailed Analysis\n",
    "The dataset appears to be a large-scale survey dataset containing 28,108 entries across 18 columns. It primarily consists of categorical and textual data, with some numerical fields related to salaries and other metrics. While the dataset provides rich information, it also presents several challenges related to missing values, formatting inconsistencies, and data type mismatches. A thorough cleaning and preprocessing process would be necessary before using it for analysis.  \r\n",
    "\r\n",
    "One of the most significant issues is the presence of missing values across multiple columns. Certain fields, such as `q4` and `q8`, have extremely high levels of missing data, making them candidates for removal or imputation. Other columns, like `q6` and `q9`, also have missing values, which might affect downstream analysis if not handled properly. Depending on the importance of these fields, various strategies such as replacing missing values with defaults, using mean/median imputation, or dropping incomplete rows may be necessary.  \r\n",
    "\r\n",
    "Another key issue is the inconsistency in data formatting. For instance, salary-related fields (`q5`) are stored as strings with commas, requiring conversion to numerical data types for proper calculations. Similarly, country and state fields (`q10` and `q11`) contain inconsistencies, such as abbreviations (\"US,\" \"USA,\" \"United States\") and variations in state names, which may require standardization. Additionally, experience-related fields (`q13` and `q14`) use different formats (e.g., \"5-7 years\" vs. \"8 - 10 years\"), which may complicate categorization and comparative analysis.  \r\n",
    "\r\n",
    "The dataset also includes categorical variables that exhibit potential inconsistencies in capitalization, spacing, and terminology. Variables such as gender (`q16`) and ethnicity (`q17`) should be checked for uniformity to prevent redundancy in category counts (e.g., \"woman\" vs. \"Woman\" or \"white\" vs. \"White\"). Standardizing all text-based responses by converting them to lowercase and stripping unnecessary spaces will improve consistency and reduce errors in analysis.  \r\n",
    "\r\n",
    "Lastly, there are data type mismatches that need attention. While most fields are stored as objects (strings), certain columns, such as `q6`, are numerical but have missing values represented as `NaN`, which could affect calculations. Converting all relevant numerical fields into appropriate data types ensures proper statistical analysis, aggregations, and visualizations. Additionally, timestamp data (`timestamp`) should be checked to ensure correct parsing if needed for time-based trends.  \r\n",
    "\r\n",
    "Overall, while the dataset contains valuable insights, it requires comprehensive data cleaning before meaningful analysis can be conducted. Addressing missing values, standardizing text formats, correcting data types, and ensuring consistency across categorical variables will significantly enhance its usability for further statistical modeling, visualization, or predictive analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320e3606-db07-41fa-a6b1-f31c3b6ffbde",
   "metadata": {},
   "source": [
    "#### The Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdfa01e-9eb1-4dcd-a5c0-a42e4b3b53a9",
   "metadata": {},
   "source": [
    "Now, it is time to plan how you will clean up the dataset. You **are not** allowed to use any machine learning technique to clean the data. (No SMOTE! No machine learning! Or anything like that!)\n",
    "\n",
    "**Question:** Based on your EDA above, detail how you would clean up this dataset. \n",
    "Things to consider: (This is not an exhaustive list)\n",
    "- Are there columns that can't be effectively cleaned? If so, why?\n",
    "- Are there columns that genuinely won't have a data value?\n",
    "- Does it make sense to segment the dataset based on specific columns when determining how to handle the missing values?\n",
    "- Are outliers a factor in this dataset?\n",
    "\n",
    "Remember preserving as much of the data as possible is the goal. That means dropping rows with a missing value somewhere might not be the best idea.\n",
    "\n",
    "[Add you answer to this markdown cell]\n",
    "\n",
    "**Answer:**\n",
    "### **Data Cleaning Strategy for the Survey Dataset**  \r\n",
    "\r\n",
    "#### **1. Handling Columns That Can’t Be Effectively Cleaned**  \r\n",
    "Certain columns in this dataset have an overwhelming amount of missing data, making them difficult to clean effectively. For example, `q4` and `q8` have an extremely high percentage of missing values (over 70-80%). If these fields are optional survey responses, their absence may be expected rather than problematic. Instead of attempting to impute these values, it may be more practical to drop these columns entirely unless domain-specific reasoning suggests their importance.  \r\n",
    "\r\n",
    "#### **2. Identifying Columns That Genuinely Won’t Have Data**  \r\n",
    "Some missing values may not necessarily indicate poor data quality but rather be a result of the survey structure. For example:  \r\n",
    "- If `q6` (a numeric field) represents a monetary value such as a bonus or additional compensation, then missing values might indicate that the respondent did not receive any. In this case, filling missing values with zero (`0`) rather than removing them could be more appropriate.  \r\n",
    "- `q9` appears to have a large portion of missing data, possibly due to being a follow-up response that only certain participants were required to answer. If this is a conditional field, then leaving missing values as \"not_applicable\" might be more logical rather than imputing them arbitrarily.  \r\n",
    "\r\n",
    "#### **3. Handling Missing Values Based on Column Relevance**  \r\n",
    "It makes sense to segment the dataset based on specific columns when addressing missing values. A blanket approach might not be ideal because different types of data require different handling methods.  \r\n",
    "- **Categorical Columns (`q1`, `q2`, `q3`, etc.)**: Missing values can be filled with `\"unknown\"` or `\"not_applicable\"` to maintain completeness without distorting patterns.  \r\n",
    "- **Numerical Columns (`q5`, `q6`)**: Missing salary values in `q5` (e.g., \"55,000\" stored as a string) need conversion to numeric types, and missing values should be examined. If salary data follows a normal distribution, mean or median imputation could be viable. If highly skewed, imputation should be based on percentile capping.  \r\n",
    "- **Location-Based Columns (`q10`, `q11`)**: Standardization is required for consistency (e.g., \"USA\" vs. \"United States\"). Missing state values should be left as `\"unknown\"` unless a reliable inference can be made based on `q10`.  \r\n",
    "\r\n",
    "#### **4. Addressing Outliers**  \r\n",
    "Since `q5` (salary) and `q6` (bonus/compensation) contain numerical data, outliers should be assessed.  \r\n",
    "- Salaries typically follow a right-skewed distribution, meaning there may be a few extreme high earners. Instead of removing them outright, applying a 99th percentile cap ensures that unrealistic values do not distort the analysis.  \r\n",
    "- If `q6` contains bonuses, large values should be investigated to ensure they are not data entry errors (e.g., misplaced decimal points).  \r\n",
    "\r\n",
    "#### **5. Standardizing Text Data**  \r\n",
    "- **Column Names:** Convert all column names to lowercase and replace spaces with underscores for consistency.  \r\n",
    "- **String Formatting:** Convert all categorical variables to lowercase and strip unnecessary spaces.  \r\n",
    "- **Experience Fields (`q13`, `q14`)**: Standardize to a single format, such as `\"2-4 years\"`, to ensure consistency when analyzing experience levels.  \r\n",
    "- **Gender (`q16`) and Ethnicity (`q17`)**: Ensure uniform formatting (e.g., \"woman\" vs. \"Woman\" should be standardized).  \r\n",
    "\r\n",
    "### **Final Cleanup Plan**  \r\n",
    "1. **Drop high-missing-value columns** (`q4`, `q8`) unless analysis requires them.  \r\n",
    "2. **Convert salary and bonus fields** (`q5`, `q6`) to numeric values after handling missing data.  \r\n",
    "3. **Standardize categorical fields** (`q1`-`q3`, `q10`-`q17`) by cleaning text formats.  \r\n",
    "4. **Address missing values contextually**, either by imputation, setting to `\"unknown\"`, or leaving as `\"not_applicable\"`.  \r\n",
    "5. **Identify and handle outliers** by capping numerical values at the 99th percentile.  \r\n",
    "6. **Ensure uniformity in experience and location-based fields** for better segmentation and visualization.  \r\n",
    "\r\n",
    "By implementing these steps, the dataset will be significantly cleaner, reducing potential errors and making it ready for meaningful analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca688475-573d-4cd7-b29a-fecf53ff6976",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69883462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Column Names: Index(['timestamp', 'q1', 'q2', 'q3', 'q4', 'q5', 'q6', 'q7', 'q8', 'q9',\n",
      "       'q10', 'q11', 'q12', 'q13', 'q14', 'q15', 'q16', 'q17'],\n",
      "      dtype='object')\n",
      "Updated Column Names: Index(['timestamp', 'q1', 'q2', 'q3', 'q4', 'q5', 'q6', 'q7', 'q8', 'q9',\n",
      "       'q10', 'q11', 'q12', 'q13', 'q14', 'q15', 'q16', 'q17'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 27826 entries, 0 to 28107\n",
      "Data columns (total 18 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   timestamp  27826 non-null  object \n",
      " 1   q1         27826 non-null  object \n",
      " 2   q2         27826 non-null  object \n",
      " 3   q3         27826 non-null  object \n",
      " 4   q4         27826 non-null  object \n",
      " 5   q5         27826 non-null  float64\n",
      " 6   q6         27826 non-null  float64\n",
      " 7   q7         27826 non-null  object \n",
      " 8   q8         27826 non-null  object \n",
      " 9   q9         27826 non-null  object \n",
      " 10  q10        27826 non-null  object \n",
      " 11  q11        27826 non-null  object \n",
      " 12  q12        27826 non-null  object \n",
      " 13  q13        27826 non-null  object \n",
      " 14  q14        27826 non-null  object \n",
      " 15  q15        27826 non-null  object \n",
      " 16  q16        27826 non-null  object \n",
      " 17  q17        27826 non-null  object \n",
      "dtypes: float64(2), object(16)\n",
      "memory usage: 4.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q3</th>\n",
       "      <th>q4</th>\n",
       "      <th>q5</th>\n",
       "      <th>q6</th>\n",
       "      <th>q7</th>\n",
       "      <th>q8</th>\n",
       "      <th>q9</th>\n",
       "      <th>q10</th>\n",
       "      <th>q11</th>\n",
       "      <th>q12</th>\n",
       "      <th>q13</th>\n",
       "      <th>q14</th>\n",
       "      <th>q15</th>\n",
       "      <th>q16</th>\n",
       "      <th>q17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>education (higher education)</td>\n",
       "      <td>research and instruction librarian</td>\n",
       "      <td>nan</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>usd</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>united states</td>\n",
       "      <td>massachusetts</td>\n",
       "      <td>boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>woman</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>computing or tech</td>\n",
       "      <td>change &amp; internal communications manager</td>\n",
       "      <td>nan</td>\n",
       "      <td>54600.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>gbp</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>nan</td>\n",
       "      <td>cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>college degree</td>\n",
       "      <td>non-binary</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>accounting, banking &amp; finance</td>\n",
       "      <td>marketing specialist</td>\n",
       "      <td>nan</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>usd</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>united_states</td>\n",
       "      <td>tennessee</td>\n",
       "      <td>chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>college degree</td>\n",
       "      <td>woman</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>nonprofits</td>\n",
       "      <td>program manager</td>\n",
       "      <td>nan</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>usd</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>united_states</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>college degree</td>\n",
       "      <td>woman</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>accounting, banking &amp; finance</td>\n",
       "      <td>accounting manager</td>\n",
       "      <td>nan</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>usd</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>united_states</td>\n",
       "      <td>south carolina</td>\n",
       "      <td>greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>college degree</td>\n",
       "      <td>woman</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp     q1                             q2  \\\n",
       "0  4/27/2021 11:02:10  25-34   education (higher education)   \n",
       "1  4/27/2021 11:02:22  25-34              computing or tech   \n",
       "2  4/27/2021 11:02:38  25-34  accounting, banking & finance   \n",
       "3  4/27/2021 11:02:41  25-34                     nonprofits   \n",
       "4  4/27/2021 11:02:42  25-34  accounting, banking & finance   \n",
       "\n",
       "                                         q3   q4       q5      q6   q7   q8  \\\n",
       "0        research and instruction librarian  nan  55000.0     0.0  usd  nan   \n",
       "1  change & internal communications manager  nan  54600.0  4000.0  gbp  nan   \n",
       "2                      marketing specialist  nan  34000.0     0.0  usd  nan   \n",
       "3                           program manager  nan  62000.0  3000.0  usd  nan   \n",
       "4                        accounting manager  nan  60000.0  7000.0  usd  nan   \n",
       "\n",
       "    q9             q10             q11          q12           q13  \\\n",
       "0  nan   united states   massachusetts       boston     5-7 years   \n",
       "1  nan  united kingdom             nan    cambridge  8 - 10 years   \n",
       "2  nan   united_states       tennessee  chattanooga   2 - 4 years   \n",
       "3  nan   united_states       wisconsin    milwaukee  8 - 10 years   \n",
       "4  nan   united_states  south carolina   greenville  8 - 10 years   \n",
       "\n",
       "           q14              q15         q16    q17  \n",
       "0    5-7 years  master's degree       woman  white  \n",
       "1    5-7 years   college degree  non-binary  white  \n",
       "2  2 - 4 years   college degree       woman  white  \n",
       "3    5-7 years   college degree       woman  white  \n",
       "4    5-7 years   college degree       woman  white  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Standardizing Column Names (removes spaces, lowercase, replaces spaces with underscores)\n",
    "print(\"Original Column Names:\", df.columns)\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "print(\"Updated Column Names:\", df.columns)  # Check updated names\n",
    "\n",
    "# 2. Handling Missing Values\n",
    "# Identify high-missing-value columns\n",
    "missing_threshold = 0.7  # Drop columns with more than 70% missing data\n",
    "cols_to_drop = [col for col in df.columns if df[col].isna().mean() > missing_threshold]\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Fill missing values contextually\n",
    "fill_values = {\n",
    "    'q6': 0,  # Assuming q6 is a numeric column where missing values imply zero\n",
    "    'q9': 'not_applicable',  # Assuming q9 is a categorical variable\n",
    "}\n",
    "df.fillna(fill_values, inplace=True)\n",
    "\n",
    "# 3. Standardizing Categorical Variables\n",
    "categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "\n",
    "# 4. Outlier Treatment (Removing extreme values in Salary and Bonus columns if applicable)\n",
    "numeric_columns = ['q5', 'q6']  # Assuming q5 (salary) and q6 (bonus) contain numerical data\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns and df[col].dtype != 'object':\n",
    "        df = df[df[col] <= df[col].quantile(0.99)]  # Cap at 99th percentile\n",
    "\n",
    "# 5. Data Type Corrections\n",
    "if 'q5' in df.columns:\n",
    "    df['q5'] = df['q5'].str.replace(',', '').astype(float)  # Convert salary to numeric\n",
    "\n",
    "# 6. Standardizing Experience and Location Fields\n",
    "if 'q10' in df.columns:\n",
    "    df['q10'] = df['q10'].replace({'usa': 'united_states', 'us': 'united_states'})  # Normalize country names\n",
    "\n",
    "if 'q13' in df.columns:\n",
    "    df['q13'] = df['q13'].str.replace(r'\\s*-\\s*', '-')  # Ensure uniform experience formatting\n",
    "\n",
    "# Display cleaned dataset info\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a286a2a7-a6b6-4f77-9e46-1f5e9602bb03",
   "metadata": {},
   "source": [
    "Based on the plan the you described above, go ahead and clean up the dataset.\n",
    "\n",
    "[Add as many code cell below here as needs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e539139-1ced-4772-95a0-60d58bb72f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49774589-0d4f-4423-bfe5-7a4e04310b2c",
   "metadata": {},
   "source": [
    "#### Reflection\n",
    "Write a short reflection (400-500 words) answering the following: \n",
    "- What were the biggest issues you encountered in the messy dataset?\n",
    "- How did cleaning the dataset improve its usability for machine learning?\n",
    "- What would happen if we trained a model on the messy dataset vs. the cleaned one?\n",
    "- Do you feel you skewed or biased the dataset while cleaning it?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Reflection on Dataset Cleaning**\r\n",
    "\r\n",
    "Cleaning the survey dataset was a crucial step in ensuring its usability for machine learning and statistical analysis. The raw dataset contained several issues that could have negatively impacted model performance if left unaddressed.\r\n",
    "\r\n",
    "One of the biggest issues in the dataset was the presence of missing values. Some columns had over 70% missing data, making them unreliable for analysis. In such cases, retaining these columns would have introduced noise rather than meaningful insights. Additionally, missing values in numerical fields like salary and bonus could distort statistical computations, while missing categorical values could lead to inconsistencies in classification tasks. Standardizing missing values by imputing or labeling them as “not_applicable” improved data integrity.\r\n",
    "\r\n",
    "Another major challenge was inconsistent text formatting in categorical variables. Variations in capitalization, extra spaces, and different representations of the same value (e.g., \"USA\" vs. \"United States\") could have led to redundant categories during encoding. By converting text to lowercase and normalizing values, we ensured consistency, reducing the risk of misclassification in categorical variables.\r\n",
    "\r\n",
    "Outliers in numerical columns, particularly in salary and bonus, also posed a challenge. Extreme values could disproportionately influence machine learning models, leading to skewed predictions. By capping values at the 99th percentile, we mitigated the impact of extreme outliers while preserving meaningful data. Additionally, some numerical columns were stored as text, which would have caused errors in computations. Converting these fields to appropriate numerical formats improved the dataset’s usability for statistical operations.\r\n",
    "\r\n",
    "Cleaning the dataset significantly improved its usability for machine learning. By standardizing formats, handling missing values, and addressing outliers, we created a more structured dataset. Machine learning algorithms perform better when they receive consistent, well-organized data. A cleaned dataset allows for more accurate feature engineering, model training, and evaluation. Without these preprocessing steps, the model might misinterpret noise as meaningful patterns, leading to poor generalization.\r\n",
    "\r\n",
    "If we trained a machine learning model on the messy dataset, we would likely see several issues. Missing values could cause errors in models that don’t handle them well, and inconsistencies in categorical variables could lead to improper encoding. Furthermore, extreme outliers could skew results, causing models to overfit to rare, unrepresentative data points. A cleaned dataset ensures that the model learns from relevant patterns rather than being influenced by inconsistencies.\r\n",
    "\r\n",
    "While cleaning the dataset, there was a potential risk of skewing or biasing the data. For example, imputing missing values or removing outliers inherently alters the dataset. If not done carefully, this process could introduce bias by overrepresenting certain patterns while underrepresenting others. To mitigate this, we made context-driven decisions, such as replacing missing categorical values with “not_applicable” rather than arbitrary placeholders. Ensuring that transformations preserved the dataset’s integrity was a priority.\r\n",
    "\r\n",
    "Overall, the cleaning process made the dataset more reliable for machine learning and analysis, ensuring that models trained on it would yield meaningful insights.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c146cde6-43d7-4be6-ada4-abbdd8377e6a",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "Upload your Jupyter Notebook to your GitHub repo and then provide a link to that repo in Worlclass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255643a1-8e6a-4615-83a4-4c0d29d55b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
